{
 "cells":[
  {
   "cell_type":"markdown",
   "source":[
    "# Introduction to neural networks\n",
    "\n",
    "CREDIT: This practical was inspired by [this Kaggle notebook on neural networks](https:\/\/www.kaggle.com\/code\/prashant111\/mnist-deep-neural-network-with-keras)."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"GVo10nb36uDS9vJ9EhxcZ4",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"JoHk2C319pxhiBaGkNQMDg"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Setup\n",
    "### Imports"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"XRS0rFPXUlRgtEHlNxcpID",
     "type":"MD",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"UcaZxTvte2AQBKxsfYBVTL"
     }
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import pandas as pd                                     # for dataset manipulation (DataFrames)\n",
    "import numpy as np                                      # allows some mathematical operations\n",
    "import matplotlib.pyplot as plt                         # library used to display graphs\n",
    "import seaborn as sns                                   # more convenient visualisation library for dataframes\n",
    "import time                                             # for execution time measurement"
   ],
   "execution_count":1,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"TbLv57fkMm1TbExf2jVxHh",
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "report_properties":{
      "rowId":"PvEHx5cM4msrC9cCg1cW9N"
     }
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "### Neural-networks-related imports\n",
    "\n",
    "There are two main libraries to work with neural networks in Python: `pytorch` (developed by Meta\/Facebook) and `tensorflow` (developed by Google).\n",
    "In this practical, we will work with `tensorflow`, and more specifically with a library that makes it easier to use: `keras`.\n",
    "The relevant imports are listed below."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"J8ZZ2JPFL7BcDWr9ASgdr5",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Neural network libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation, Dropout\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import  backend as K"
   ],
   "execution_count":2,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"QfScVrHFDjN9Xwj4mdY1lw",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Importing and observing the data\n",
    "\n",
    "For this introduction to neural networks, we will be working with the well-known MNIST handwritten digits dataset.\n",
    "This dataset can be imported directly from `keras`. You'll note that, unlike `scikit-learn`, `keras` already separates the data into a training and test set.\n",
    "\n",
    "Once you have imported the data, answer the following questions:\n",
    "1. What are the shapes of `x_train`, `y_train`, `x_test`, `y_test`? What does it mean?\n",
    "2. What is the proportion of test data?\n",
    "3. How many classes are there? What are they? Are they balanced?"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"lqpL20bjkfGlehb5Klwwbt",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from keras.datasets import mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ],
   "execution_count":3,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"xboa1kXChth2v07ShH81Br",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Your code here"
   ],
   "execution_count":4,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"1QwowMEInr22d1UtrgGbJt",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "*[Your comments here]*"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"yOnYDE88XUKrFrJPjOmFNE",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "The code below will let you visualize random samples from the training dataset.\n",
    "\n",
    "**[Bonus]** Add comments to the code to explain how it works."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"zxl9D4XwpHHgd8pYYROIZg",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# ...\n",
    "indexes = np.random.randint(0, x_train.shape[0], size=25)\n",
    "images = x_train[indexes]\n",
    "labels = y_train[indexes]\n",
    "\n",
    "\n",
    "# ...\n",
    "plt.figure(figsize=(5,5))\n",
    "for i in range(len(indexes)):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    image = images[i]\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ],
   "execution_count":5,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"0jpAW6WBdFMloeHUKZPpF6",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Preparing the data\n",
    "\n",
    "1. Determine the minimum and maximum value for pixels in the image.\n",
    "2. Scale `x_train` and `x_test` to make sure their values remain between 0 and 1. This prevents gradients from becoming too large during backpropagation.\n",
    "3. Reshape the matrices so that every input is 1D. For example, `x_train`'s shape should be `(number of samples, size of an image)`.\n",
    "\n",
    "We want the network to output a probability for each class. Therefore, the current representation of labels is not suitable. We need to convert the current labels into binary vectors of size 10. This is called [one-hot encoding](https:\/\/en.wikipedia.org\/wiki\/One-hot)\n",
    "\n",
    "4. Using the `to_categorical` function, perform one-hot encoding for `y_train` and `y_test`.\n",
    "\n",
    "Your data is not ready to be used in a neural network!\n",
    " "
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"patFDqqZ7DPV8WWDVtQFtW",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Your code here"
   ],
   "execution_count":6,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"tYVdxVC8BkXZVEbjl5wOEV",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "*[Your comments here]*"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"wkd0QxJY73831rjIqnO5H3",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Building the network\n",
    "\n",
    "In this section, we will build a neural network using `keras`.\n",
    "\n",
    "In the following cell, we define some parameters that will be used in the network."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"Z9H9EoAc4o1rR3gvZu0Uyg",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "batch_size = 128 # indicates the number of data that we will use for each update of the model parameters\n",
    "hidden_units = 256 # number of units in the hidden layers\n",
    "dropout = 0.45 # dropout rate"
   ],
   "execution_count":7,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"tV2Qh0ZCiU4lzdbfzC5ksd",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "We will build the network in the following cell. Using the examples provided, complete the network architecture."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"m2xubYyz9YwUWBDmclogFs",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "model = Sequential() # initialize the network as a sequence of layers\n",
    "model.add(Dense(hidden_units, input_dim=...)) # input_dim corresponds to the input size, i.e. the number of pixels\n",
    "model.add(Activation('relu')) # defines the activation function\n",
    "model.add(Dropout(dropout)) # dropout layers randomly sets input units to 0 to prevent overfitting\n",
    "# add another dense layer here with the same number of units (the input_dim parameter is not required this time)\n",
    "# add another relu activation function\n",
    "# add another dropout layer with the same dropout rate\n",
    "# add the output layer (dense layer with as many units as there are possible outputs)\n",
    "# add a softmax activation (the softmax function returns a value between 0 and 1, which is interpreted as a probability)"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"2PT2fxngAJpkIoK8uIj7aX",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Using the `summary` function, find out how many parameters the model has. What comments can you make?\n",
    "\n",
    "**[Bonus]** Justify the amount of parameters."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"L3LAQ51v4zCanc5cxrC3L1",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Training the network\n",
    "\n",
    "In order to be used, a model needs to be compiled. In the cell below, explain what each of the parameters are (either as code comments or markdown text)."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"RhaRENgqwbzJYeifa2fufF",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# model is a 3-layer MLP with ReLU and dropout after each layer\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_units, input_dim=28*28))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(hidden_units))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ],
   "execution_count":19,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"mDN6fE8P3WHebMxcd2zmvU",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "model.compile(loss='categorical_crossentropy', # ...\n",
    "              optimizer='adam', # ...\n",
    "              metrics=['accuracy']) # ..."
   ],
   "execution_count":20,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"MhA2A0F4D8YURPihbVicqb",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "The model can then be fit to our data and its performance can be measured. Interpret the results you obtained."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"cGqoJ25DXAjvGuwWysooq7",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "model.fit(x_train, y_train, epochs=20, batch_size=batch_size)"
   ],
   "execution_count":21,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"ll1as327Of5uSJgmaiKlb8",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"RCQNDNpRxXgkZNkPb6nl4H",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "Congratulations! You have successfully built and trained a simple neural network!"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"8IXkFd9fAZgNVaPRWdykJS",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Bonus questions\n",
    "\n",
    "Try changing the parameters and architecture of the model, and comment on any changes you observe."
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"NqkZCjuLSpgjcsWVUkn79C",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "*[Your comments here]*"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"u5EaBaWLbVRtmqCUkl03oC",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Your code here"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"8Uw6xPJ7QQ7YTGhCCWnSXT",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    {
     "name":"graphviz",
     "version":"0.20.1",
     "source":"PIP"
    }
   ],
   "report_row_ids":[
    "JoHk2C319pxhiBaGkNQMDg",
    "UcaZxTvte2AQBKxsfYBVTL",
    "PvEHx5cM4msrC9cCg1cW9N",
    "88aGZKjbW2yebOUDzoYtf1",
    "fTZ8YWjegGDKILAMu1D44H",
    "HWQmszIy97KJ1RhraFUAj8",
    "JuCjblwngnvBdfqezYhilA",
    "aBltzOrMTRxDSy0ZNPzYHb",
    "WQafdfYaFmr4q44RPvLyJb",
    "HJbPfYQCr5TUK3CPEuiAKs",
    "b9jr8VKK89SanxajR65i20",
    "Xa86OEruzAcfgy1yLvogKb",
    "Ckq38I69B3KQnn3Jbyi3re",
    "EwsEGtNBOPdgD6K6wmAiiD",
    "0p61ATR4JOGt74Cgrd10Nj",
    "P9l3UkPXvxi6tPvYFZV6Lj",
    "T4GPV8l4bUkW9fiHtP1PqI",
    "lVKEpvgJSu6x8mEotFcbO9",
    "1e0m1jgvZl9f5gxqAVVPzV",
    "yB9vNEzq8slDwpUBl5UWhm",
    "RCLbNOz5te9A83IbKRJsTR",
    "hEQmNI6MOoBEBQYnExGp2K",
    "m5bakJ18PgHb9SMNwRKkiu",
    "dq50A9krJH464ellM28HIb"
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}