{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imbalanced data\n",
    "\n",
    "CREDIT: This practical was inspired from [this notebook on imbalanced datasets](https://colab.research.google.com/github/littlecolumns/ds4j-notebooks/blob/master/classification/notebooks/Correcting%20for%20imbalanced%20datasets.ipynb#scrollTo=gvj-ZuWOoO_2)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a38b27fe449e0a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc08d55eff3bde78"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd                                     # for dataset manipulation (DataFrames)\n",
    "import numpy as np                                      # allows some mathematical operations\n",
    "import matplotlib.pyplot as plt                         # library used to display graphs\n",
    "import seaborn as sns                                   # more convenient visualisation library for dataframes\n",
    "from sklearn.model_selection import train_test_split    # for classification\n",
    "from sklearn.svm import LinearSVC                       # for classification\n",
    "from sklearn.metrics import confusion_matrix            # for classification\n",
    "from sklearn.metrics import accuracy_score              # for classification\n",
    "import imblearn                                         # for imbalance management\n",
    "import time                                             # for execution time measurement"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa0eec42147672be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "106a61f3a95a0f42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_recipes_balanced = pd.read_csv(\"recipes_balanced.csv\")\n",
    "df_recipes = pd.read_csv(\"recipes.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9f584479ff47673"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Observing the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e7d0ce908dfd69f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using what you have learned in the previous lessons, examine the datasets and see what you can learn about them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d41eba79f955889"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b29f8f86fa138c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Your comments here]*"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eac68b386dee986b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification task\n",
    "\n",
    "The goal with these datasets will be to detect which recipes are Indian."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Data Labeling\n",
    "For each dataset, add a column named `is_indian`, indicating whether the recipe is indian (1) or not (0).\n",
    "The labeling should be done in place, meaning that we should keep the same dataframes instead of creating new ones."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Observing the classes\n",
    "\n",
    "1. For both datasets, compare the number of examples for each class. What do you notice?\n",
    "2. Use an appropriate graph to display your observations.\n",
    "3. What problem(s) can this cause for our classification task?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Your comments here]*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline test\n",
    "#### Data preparation\n",
    "In order to perform the classification, we first need to convert the ingredient lists into vectors. For this, we will use a TF-IDF vectorizer. Details about this vectorizer, and more insights on how to work with text will be given in the dedicated practical. For now, just use it as is!\n",
    "\n",
    "*NB: We should use the vectorizer after the train-test split, but we will overlook this issue in this practical.*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a vectorizer for each dataset and train it\n",
    "vectorizer_balanced = TfidfVectorizer()\n",
    "ingredients_balanced = vectorizer_balanced.fit_transform(df_recipes_balanced.ingredient_list).toarray()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "ingredients = vectorizer.fit_transform(df_recipes.ingredient_list).toarray()\n",
    "\n",
    "# In the classification task, the features X are the ingredients, and the label y is whether the recipe is Indian\n",
    "X_balanced = ingredients_balanced\n",
    "y_balanced = df_recipes_balanced.is_indian\n",
    "\n",
    "X = ingredients\n",
    "y = df_recipes.is_indian"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train_balanced,  X_test_balanced, y_train_balanced, y_test_balanced = train_test_split(X_balanced, y_balanced, stratify=y_balanced)\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question**: In the above cell, what does the \"stratify\" parameter do in the train-test split?\n",
    "\n",
    "*[Your answer here]*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Baseline classification\n",
    "\n",
    "For this first test, we will use a linear classifier called LinearSVC."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def classify(input_train, input_test, label_train, label_test):\n",
    "    classifier = LinearSVC()\n",
    "    classifier.fit(input_train, label_train)\n",
    "\n",
    "    label_predicted = classifier.predict(input_test)\n",
    "    label_true = label_test\n",
    "\n",
    "    classification_confusion_matrix = confusion_matrix(label_true, label_predicted)\n",
    "    label_names = pd.Series(['not indian', 'indian'])\n",
    "\n",
    "    print(f\"Accuracy:{accuracy_score(label_true, label_predicted)}\")\n",
    "    return pd.DataFrame(classification_confusion_matrix,\n",
    "                 columns='Predicted ' + label_names,\n",
    "                 index='Is ' + label_names)\\\n",
    "        .div(classification_confusion_matrix.sum(axis=1), axis=0) # converts the numbers into percentages\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test on the balanced dataset\n",
    "classify(X_train_balanced, X_test_balanced, y_train_balanced, y_test_balanced)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test on the imbalanced dataset\n",
    "classify(X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Questions\n",
    "1. The matrices shown above are called \"confusion matrices\". Describe what they contain.\n",
    "2. What do you think is the advantage of using a confusion matrix over using accuracy alone?\n",
    "3. Compare the results obtained with the balanced dataset and with the imbalanced dataset. What are the main differences?\n",
    "4. How do you interpret these differences?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Your comments here]*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Managing the imbalance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Undersampling and oversampling\n",
    "\n",
    "In this section, we will use 3 different resampling techniques: random undersampling, random oversampling, and SMOTE. We will only need the `df_recipes` dataframe (the balanced dataframe will not be used anymore).\n",
    "For each of those three techniques, answer the following questions:\n",
    "1. Using your knowledge and [`imblearn`'s documentation](https://imbalanced-learn.org/stable/references/index.html), explain the principle of the algorithm.\n",
    "2. Import and instantiate the resampler.\n",
    "3. Use it to resample the data. On what part of the data should you use the resampler?\n",
    "4. Observe and comment on the resampling of the classes.\n",
    "5. Use the `classify` function from earlier to observe the influence of the resampling on classification.\n",
    "6. Comment on your results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random undersampling\n",
    "\n",
    "*[Your answers here]*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random oversampling\n",
    "\n",
    "*[Your answers here]*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SMOTE\n",
    "\n",
    "*[Your answers here]*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bonus: using other methods\n",
    "\n",
    "There are many methods to deal with imbalanced learning. Check out [`imblearn`'s documentation](https://imbalanced-learn.org/stable/references/index.html) and try using other algorithms. Try to increase the performance of the classification!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Your code here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*[Your comments here]*"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
